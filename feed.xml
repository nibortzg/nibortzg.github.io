<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://nibortzg.github.io/</id><title>Nibor</title><subtitle>Computer vision, Artificial intelligence Paper review &amp; Travel</subtitle> <updated>2022-01-23T21:20:25-08:00</updated> <author> <name>your_full_name</name> <uri>https://nibortzg.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://nibortzg.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://nibortzg.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator> <rights> © 2022 your_full_name </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>(論文筆記) Designing Network Design Spaces -> Regnet</title><link href="https://nibortzg.github.io/posts/Designing-Network-Design-Space/" rel="alternate" type="text/html" title="(論文筆記) Designing Network Design Spaces -> Regnet" /><published>2021-01-23T12:30:00-08:00</published> <updated>2022-01-23T21:20:07-08:00</updated> <id>https://nibortzg.github.io/posts/Designing-Network-Design-Space/</id> <content src="https://nibortzg.github.io/posts/Designing-Network-Design-Space/" /> <author> <name>{"name"=>"Nibor", "link"=>nil}</name> </author> <category term="Computer Vision" /> <category term="Design Paragigm" /> <summary> 前言: 這篇論文試圖使用統計的方法來縮減design space，一步步的將AnyNet 縮減成RegNet, 並結總結出幾個有用的設計準則。雖然模型只在imagenet 上 train 10 epoch 讓公信力有點不足，不仍然值得嘗試。 方法: 首先作者先定義了一種AnyNet, 而這個Anynet由以下幾種參數定義，每個stage的block 數量 $d_i$ ,每個stage寬度(channels) $w_i$ , bottleneck ratio $b_i$, group width $g_i$ (如果 $g_i == 1$ 則為depthwise convolution) 如何將AnyNet的搜索空間縮減過程就不深究，有興趣直接看一下論文，基本上都是作者對於EDF(Empirical distrubution function)的比較，然後選定優化方向。 在縮... </summary> </entry> <entry><title>(論文筆記) A ConvNet for the 2020s</title><link href="https://nibortzg.github.io/posts/A-ConvNet-for-the-2020s/" rel="alternate" type="text/html" title="(論文筆記) A ConvNet for the 2020s" /><published>2021-01-20T02:33:00-08:00</published> <updated>2022-01-23T21:14:33-08:00</updated> <id>https://nibortzg.github.io/posts/A-ConvNet-for-the-2020s/</id> <content src="https://nibortzg.github.io/posts/A-ConvNet-for-the-2020s/" /> <author> <name>{"name"=>"Nibor", "link"=>nil}</name> </author> <category term="Computer Vision" /> <category term="Design Paragigm" /> <summary> 前言: 近幾年vision transformer 在各種會議上大放異彩, 隨著演進, 我們也可以發現transformer 引進越來越多跟CNN 相關的prior, 像是swin transformer的local window 就很有ConvNet的味道。觀察中可以發現vision transformer 和 CNN 變得越來越像, 且在一些下游任務中, 這些內建於CNN之中的bias會使得任務更好完成, 例如translation equivariance 對於object detection任務而言就很重要。 第二， 對於現在vision transformer 成功的關鍵，是在於transformer 本身，還是training techniques與一些其餘組件的改動，造成整體performance 的提升也是值得思考得問題，例如專精於training techniqu... </summary> </entry> </feed>
